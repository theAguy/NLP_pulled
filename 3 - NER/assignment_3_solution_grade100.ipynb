{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP HW3 - NER - 204502926_311132468_304997067",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-WJBimYDLJS"
      },
      "source": [
        "# Assignment 3\n",
        "Training a simple neural named entity recognizer (NER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3enPCGBF8FlX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# our additional imports:\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5QSIEoyDdWh"
      },
      "source": [
        "In this assignment you are required to build a full training and testing pipeline for a neural sequentail tagger for named entities, using LSTM.\n",
        "\n",
        "The dataset that you will be working on is called ReCoNLL 2003, which is a corrected version of the CoNLL 2003 dataset: https://www.clips.uantwerpen.be/conll2003/ner/\n",
        "\n",
        "\n",
        "The three files (train, test and eval) are available from the course git repository (https://github.com/kfirbar/nlp-course)\n",
        "\n",
        "As you can see, the annotated texts are labeled according to the IOB annotation scheme, for 3 entity types: Person, Organization, Location."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ul2Y3vuPoV8"
      },
      "source": [
        "**Task 1:** Write a funtion *read_data* for reading the data from a single file (either train, test or eval). This function recieves a filepath and returns a list of sentence. Every sentence is encoded as a pair of lists, one list contains the words and one list contains the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuVIYOh_tJdE",
        "outputId": "3468ce86-a44c-445a-8187-9dd2e547f4ec"
      },
      "source": [
        "!git clone https://github.com/kfirbar/nlp-course"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp-course'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 71 (delta 29), reused 40 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prgzgtt8Jw4Y"
      },
      "source": [
        "def read_data(filepath):\n",
        "    data = []\n",
        "    \n",
        "    # TODO... write your code accordingly\n",
        "    with open(filepath) as file:\n",
        "        words = []\n",
        "        labels = []\n",
        "\n",
        "        for index, line in enumerate(file, start=1):\n",
        "            if line != '\\n':\n",
        "                word, label = line.split()\n",
        "                words.append(word)\n",
        "                labels.append(label)\n",
        "            else:\n",
        "                data.append((words, labels))\n",
        "                words = []\n",
        "                labels = []\n",
        "    \n",
        "    return data\n",
        "\n",
        "\n",
        "train = read_data('/content/nlp-course/connl03_train.txt')\n",
        "test = read_data('/content/nlp-course/connl03_test.txt')\n",
        "dev = read_data('/content/nlp-course/connl03_dev.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuGwk6OwRWGS"
      },
      "source": [
        "The following Vocab class can be served as a dictionary that maps words and tags into Ids. The UNK_TOKEN should be used for words that are not part of the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rKIB5o_vQO8"
      },
      "source": [
        "UNK_TOKEN = 0\n",
        "\n",
        "\n",
        "class Vocab:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.word2id = {\"__unk__\": UNK_TOKEN}\n",
        "        self.id2word = {UNK_TOKEN: \"__unk__\"}\n",
        "        self.n_words = 1\n",
        "        \n",
        "        self.tag2id = {\"O\":0, \"B-PER\":1, \"I-PER\": 2, \"B-LOC\": 3, \"I-LOC\": 4, \"B-ORG\": 5, \"I-ORG\": 6}\n",
        "        self.id2tag = {0:\"O\", 1:\"B-PER\", 2:\"I-PER\", 3:\"B-LOC\", 4:\"I-LOC\", 5:\"B-ORG\", 6:\"I-ORG\"}\n",
        "    \n",
        "    \n",
        "    def index_words(self, words):\n",
        "        word_indexes = [self.index_word(w) for w in words]\n",
        "        return word_indexes\n",
        "\n",
        "\n",
        "    def index_tags(self, tags):\n",
        "        tag_indexes = [self.tag2id[t] for t in tags]\n",
        "        return tag_indexes\n",
        "    \n",
        "\n",
        "    def index_word(self, w):\n",
        "        if w not in self.word2id:\n",
        "            self.word2id[w] = self.n_words\n",
        "            self.id2word[self.n_words] = w\n",
        "            self.n_words += 1\n",
        "        \n",
        "        return self.word2id[w]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDKYryfKfNdh"
      },
      "source": [
        "**Task 2:** Write a function *prepare_data* that takes one of the [train, dev, test] and the Vocab instance, for converting each pair of (words,labels) to a pair of indexes (from Vocab). Each pair should be added to *data_sequences*, which is returned back from the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noIY3zWKvhBd"
      },
      "source": [
        "vocab = Vocab()\n",
        "\n",
        "\n",
        "def prepare_data(data, vocab):\n",
        "    data_sequences = []\n",
        "    \n",
        "    # TODO - your code...\n",
        "    for words, labels in data:\n",
        "        # in case we DON'T want to save them as tensors:\n",
        "        # data_sequences.append((vocab.index_words(words), vocab.index_tags(labels)))\n",
        "\n",
        "        # in case we DO want to save them as tensors:\n",
        "        words_indexes_tensor = torch.tensor(vocab.index_words(words), dtype=torch.long)\n",
        "        tags_indexes_tensor = torch.tensor(vocab.index_tags(labels), dtype=torch.long)\n",
        "        data_sequences.append((words_indexes_tensor, tags_indexes_tensor))\n",
        "\n",
        "    return data_sequences, vocab\n",
        "\n",
        "\n",
        "train_sequences, vocab = prepare_data(train, vocab)\n",
        "dev_sequences, vocab = prepare_data(dev, vocab)\n",
        "test_sequences, vocab = prepare_data(test, vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UccfiRRtiEet"
      },
      "source": [
        "**Task 3:** Write NERNet, a PyTorch Module for labeling words with NER tags. \n",
        "\n",
        "*input_size:* the size of the vocabulary\n",
        "\n",
        "*embedding_size:* the size of the embeddings\n",
        "\n",
        "*hidden_size:* the LSTM hidden size\n",
        "\n",
        "*output_size:* the number tags we are predicting for\n",
        "\n",
        "*n_layers:* the number of layers we want to use in LSTM\n",
        "\n",
        "*directions:* could 1 or 2, indicating unidirectional or bidirectional LSTM, respectively\n",
        "\n",
        "The input for your forward function should be a single sentence tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke1LyUQNyQaM"
      },
      "source": [
        "class NERNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, n_layers, directions):\n",
        "        super(NERNet, self).__init__()\n",
        "        # TODO: your code...\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.lstm = nn.LSTM(embedding_size, hidden_size, n_layers, bidirectional=(True if directions==2 else False))\n",
        "        self.out = nn.Linear(hidden_size*directions, output_size)\n",
        "    \n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.directions = directions\n",
        "\n",
        "\n",
        "    def forward(self, input_sentence):\n",
        "        # TODO: your code...\n",
        "        dimension = len(input_sentence)\n",
        "\n",
        "        # Maybe not needed:\n",
        "        # hidden_state = torch.randn(self.n_layers * self.directions, 1, self.hidden_size).cuda()\n",
        "        # cell_state = torch.randn(self.n_layers * self.directions, 1, self.hidden_size).cuda()\n",
        "        # hidden = (hidden_state, cell_state)\n",
        "        hidden = None\n",
        "\n",
        "        # 1. embed the sentence\n",
        "        embedded = self.embedding(input_sentence)\n",
        "\n",
        "        # 2. give the embedding to LSTM\n",
        "        # \"If (h_0, c_0) is not provided, both h_0 and c_0 default to zero\" (https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
        "        lstm_output, _ = self.lstm(embedded.view(dimension, 1, -1), hidden) # The view function is meant to reshape the tensor https://stackoverflow.com/a/48650355/7786691\n",
        "\n",
        "        # 3. run output through prediction function\n",
        "        output = self.out(lstm_output.view(dimension, -1)) # Applies a linear transformation to the incoming data\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEGSQdeUkTP8"
      },
      "source": [
        "**Task 4:** write a training loop, which takes a model (instance of NERNet) and number of epochs to train on. The loss is always CrossEntropyLoss and the optimizer is always Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avkHfjT3k0HM"
      },
      "source": [
        "def train_loop(model, n_epochs):\n",
        "    # Loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimizer (ADAM is a fancy version of SGD)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "  \n",
        "    # shuffle data before training phase (added by Ofir)\n",
        "    shuffle(train_sequences)\n",
        "    STEP = 400 \n",
        "\n",
        "    for e in range(1, n_epochs + 1):\n",
        "        # TODO - your code goes here...\n",
        "        for i, sequence in enumerate(train_sequences):\n",
        "            sentence, labels = sequence\n",
        "            sentence_tensor = torch.LongTensor(sentence).cuda()\n",
        "            labels_tensor = torch.LongTensor(labels).cuda()\n",
        "\n",
        "            if len(sentence_tensor) == 0:\n",
        "                continue\n",
        "\n",
        "            model.zero_grad()\n",
        "            scores = model(sentence_tensor)\n",
        "            criterion(scores, labels_tensor).backward()\n",
        "            optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baN1c_B7lTjb"
      },
      "source": [
        "**Task 5:** write an evaluation loop on a trained model, using the dev and test datasets. This function print the true positive rate (TPR), also known as Recall and the opposite to false positive rate (FPR), also known as precision, of each label seperately (7 labels in total), and for all the 6 labels (except O) together. The caption argument for the function should be served for printing, so that when you print include it as a prefix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyQAjGaqmd8U"
      },
      "source": [
        "def evaluate(model, caption):\n",
        "    # TODO - your code goes here\n",
        "    # from Piazza: https://piazza.com/class/klxc3m1tzqz2o8?cid=59\n",
        "\n",
        "    all_target_names = [\"O\", \"B-PER\", \"I-PER\", \"B-LOC\", \"I-LOC\", \"B-ORG\", \"I-ORG\"]\n",
        "    binary_target_names = [\"O\", \"OTHERS\"]\n",
        "\n",
        "    print(f\"****************    Results for {caption}    ****************\")\n",
        "\n",
        "    # evaluate test\n",
        "    all_test_words_pred = []\n",
        "    all_test_words_true = []\n",
        "    binary_test_words_pred = []\n",
        "    binary_test_words_true = []\n",
        "\n",
        "    all_dev_words_pred = []\n",
        "    all_dev_words_true = []\n",
        "    binary_dev_words_pred = []\n",
        "    binary_dev_words_true = []\n",
        "\n",
        "    for sentence, labels in test_sequences:\n",
        "        sentence_tensor = torch.LongTensor(sentence).cuda()\n",
        "        labels_tensor = torch.LongTensor(labels).cuda()\n",
        "        \n",
        "        _, pred_labels = model(sentence_tensor).T.max(0)\n",
        "\n",
        "        all_test_words_pred += pred_labels.tolist()\n",
        "        all_test_words_true += labels.tolist()\n",
        "        \n",
        "        binary_test_words_pred += [1 if i >=1 else i for i in all_test_words_pred]\n",
        "        binary_test_words_true += [1 if i >=1 else i for i in all_test_words_true]\n",
        "\n",
        "    # evaluate dev\n",
        "    for sentence, labels in dev_sequences:\n",
        "        sentence_tensor = torch.LongTensor(sentence).cuda()\n",
        "        labels_tensor = torch.LongTensor(labels).cuda()\n",
        "        \n",
        "        _, pred_labels = model(sentence_tensor).T.max(0)\n",
        "\n",
        "        all_dev_words_pred += pred_labels.tolist()\n",
        "        all_dev_words_true += labels.tolist()\n",
        "    \n",
        "        binary_dev_words_pred += [1 if i >=1 else i for i in all_dev_words_pred]\n",
        "        binary_dev_words_true += [1 if i >=1 else i for i in all_dev_words_true]\n",
        "\n",
        "    print(\"ALL Test Results:\")\n",
        "    print(classification_report(all_test_words_true, all_test_words_pred, target_names=all_target_names))\n",
        "\n",
        "    print(\"ALL Dev Results:\")\n",
        "    print(classification_report(all_dev_words_true, all_dev_words_pred, target_names=all_target_names))\n",
        "\n",
        "    print(\"BINARY Test Results:\")\n",
        "    print(classification_report(binary_test_words_true, binary_test_words_pred, target_names=binary_target_names))\n",
        "\n",
        "    print(\"BINARY Dev Results:\")\n",
        "    print(classification_report(binary_dev_words_true, binary_dev_words_pred, target_names=binary_target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQSXqWNOmqG4"
      },
      "source": [
        "**Task 6:** Train and evaluate a few models, all with embedding_size=300, and with the following hyper parameters (you may use that as captions for the models as well):\n",
        "\n",
        "Model 1: (hidden_size: 500, n_layers: 1, directions: 1)\n",
        "\n",
        "Model 2: (hidden_size: 500, n_layers: 2, directions: 1)\n",
        "\n",
        "Model 3: (hidden_size: 500, n_layers: 3, directions: 1)\n",
        "\n",
        "Model 4: (hidden_size: 500, n_layers: 1, directions: 2)\n",
        "\n",
        "Model 5: (hidden_size: 500, n_layers: 2, directions: 2)\n",
        "\n",
        "Model 6: (hidden_size: 500, n_layers: 3, directions: 2)\n",
        "\n",
        "Model 7: (hidden_size: 800, n_layers: 1, directions: 2)\n",
        "\n",
        "Model 8: (hidden_size: 800, n_layers: 2, directions: 2)\n",
        "\n",
        "Model 9: (hidden_size: 800, n_layers: 3, directions: 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTNmBU6hycZl"
      },
      "source": [
        "# TODO - your code goes here...\n",
        "EMBEDDING_SIZE = 300\n",
        "EPOCHS = 10\n",
        "INPUT_SIZE = len(vocab.word2id) # 8955\n",
        "OUTPUT_SIZE = len(vocab.tag2id) # 7\n",
        "\n",
        "model_1 = NERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 1, 1).cuda()\n",
        "train_loop(model_1, EPOCHS)\n",
        "\n",
        "model_2 = NERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 2, 1).cuda()\n",
        "train_loop(model_2, EPOCHS)\n",
        "\n",
        "model_3 = NERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 3, 1).cuda()\n",
        "train_loop(model_3, EPOCHS)\n",
        "\n",
        "model_4 = NERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 1, 2).cuda()\n",
        "train_loop(model_4, EPOCHS)\n",
        "\n",
        "model_5 = NERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 2, 2).cuda()\n",
        "train_loop(model_5, EPOCHS)\n",
        "\n",
        "model_6 = NERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 3, 2).cuda()\n",
        "train_loop(model_6, EPOCHS)\n",
        "\n",
        "model_7 = NERNet(INPUT_SIZE, EMBEDDING_SIZE, 800, OUTPUT_SIZE, 1, 2).cuda()\n",
        "train_loop(model_7, EPOCHS)\n",
        "\n",
        "model_8 = NERNet(INPUT_SIZE, EMBEDDING_SIZE, 800, OUTPUT_SIZE, 2, 2).cuda()\n",
        "train_loop(model_8, EPOCHS)\n",
        "\n",
        "model_9 = NERNet(INPUT_SIZE, EMBEDDING_SIZE, 800, OUTPUT_SIZE, 3, 2).cuda()\n",
        "train_loop(model_9, EPOCHS)\n",
        "\n",
        "\n",
        "models = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7qXvLT_fRBL",
        "outputId": "08680c0e-d9e9-4ff5-8bc1-2e62507f38bf"
      },
      "source": [
        "for i, model in enumerate(models, start=1):\n",
        "    model_name = \"model_\"+str(i)\n",
        "    evaluate(model, model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************    Results for model_1    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.92      0.97      0.94      6567\n",
            "       B-PER       0.72      0.62      0.67       434\n",
            "       I-PER       0.79      0.71      0.75       296\n",
            "       B-LOC       0.82      0.69      0.75       343\n",
            "       I-LOC       0.85      0.62      0.72        53\n",
            "       B-ORG       0.58      0.54      0.56       350\n",
            "       I-ORG       0.66      0.30      0.42       200\n",
            "\n",
            "    accuracy                           0.89      8243\n",
            "   macro avg       0.76      0.64      0.69      8243\n",
            "weighted avg       0.88      0.89      0.88      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.92      0.97      0.94      3096\n",
            "       B-PER       0.75      0.66      0.70       200\n",
            "       I-PER       0.89      0.69      0.77       157\n",
            "       B-LOC       0.77      0.67      0.72       183\n",
            "       I-LOC       1.00      0.43      0.61        23\n",
            "       B-ORG       0.60      0.57      0.58       168\n",
            "       I-ORG       0.77      0.40      0.52       116\n",
            "\n",
            "    accuracy                           0.89      3943\n",
            "   macro avg       0.81      0.63      0.69      3943\n",
            "weighted avg       0.89      0.89      0.88      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.92      0.96      0.94   1616269\n",
            "      OTHERS       0.83      0.69      0.75    423980\n",
            "\n",
            "    accuracy                           0.90   2040249\n",
            "   macro avg       0.87      0.82      0.85   2040249\n",
            "weighted avg       0.90      0.90      0.90   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.92      0.97      0.94    380877\n",
            "      OTHERS       0.87      0.72      0.79    113647\n",
            "\n",
            "    accuracy                           0.91    494524\n",
            "   macro avg       0.90      0.84      0.87    494524\n",
            "weighted avg       0.91      0.91      0.91    494524\n",
            "\n",
            "****************    Results for model_2    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.97      0.95      6567\n",
            "       B-PER       0.75      0.68      0.71       434\n",
            "       I-PER       0.76      0.74      0.75       296\n",
            "       B-LOC       0.79      0.77      0.78       343\n",
            "       I-LOC       0.96      0.51      0.67        53\n",
            "       B-ORG       0.69      0.56      0.62       350\n",
            "       I-ORG       0.68      0.39      0.49       200\n",
            "\n",
            "    accuracy                           0.90      8243\n",
            "   macro avg       0.80      0.66      0.71      8243\n",
            "weighted avg       0.90      0.90      0.90      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.93      0.97      0.95      3096\n",
            "       B-PER       0.71      0.70      0.71       200\n",
            "       I-PER       0.79      0.75      0.76       157\n",
            "       B-LOC       0.78      0.72      0.75       183\n",
            "       I-LOC       0.91      0.43      0.59        23\n",
            "       B-ORG       0.73      0.57      0.64       168\n",
            "       I-ORG       0.85      0.48      0.62       116\n",
            "\n",
            "    accuracy                           0.90      3943\n",
            "   macro avg       0.81      0.66      0.72      3943\n",
            "weighted avg       0.90      0.90      0.90      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.93      0.97      0.95   1616269\n",
            "      OTHERS       0.87      0.74      0.80    423980\n",
            "\n",
            "    accuracy                           0.92   2040249\n",
            "   macro avg       0.90      0.85      0.87   2040249\n",
            "weighted avg       0.92      0.92      0.92   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.93      0.97      0.95    380877\n",
            "      OTHERS       0.89      0.75      0.82    113647\n",
            "\n",
            "    accuracy                           0.92    494524\n",
            "   macro avg       0.91      0.86      0.88    494524\n",
            "weighted avg       0.92      0.92      0.92    494524\n",
            "\n",
            "****************    Results for model_3    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.93      0.98      0.95      6567\n",
            "       B-PER       0.76      0.65      0.70       434\n",
            "       I-PER       0.78      0.66      0.71       296\n",
            "       B-LOC       0.82      0.70      0.76       343\n",
            "       I-LOC       0.90      0.53      0.67        53\n",
            "       B-ORG       0.70      0.52      0.60       350\n",
            "       I-ORG       0.59      0.29      0.39       200\n",
            "\n",
            "    accuracy                           0.90      8243\n",
            "   macro avg       0.78      0.62      0.68      8243\n",
            "weighted avg       0.89      0.90      0.89      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.92      0.98      0.95      3096\n",
            "       B-PER       0.72      0.64      0.68       200\n",
            "       I-PER       0.89      0.65      0.75       157\n",
            "       B-LOC       0.79      0.65      0.71       183\n",
            "       I-LOC       0.50      0.35      0.41        23\n",
            "       B-ORG       0.66      0.52      0.58       168\n",
            "       I-ORG       0.71      0.31      0.43       116\n",
            "\n",
            "    accuracy                           0.89      3943\n",
            "   macro avg       0.74      0.59      0.64      3943\n",
            "weighted avg       0.88      0.89      0.88      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.92      0.98      0.95   1616269\n",
            "      OTHERS       0.89      0.69      0.77    423980\n",
            "\n",
            "    accuracy                           0.92   2040249\n",
            "   macro avg       0.90      0.83      0.86   2040249\n",
            "weighted avg       0.91      0.92      0.91   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.92      0.98      0.95    380877\n",
            "      OTHERS       0.92      0.70      0.79    113647\n",
            "\n",
            "    accuracy                           0.92    494524\n",
            "   macro avg       0.92      0.84      0.87    494524\n",
            "weighted avg       0.92      0.92      0.91    494524\n",
            "\n",
            "****************    Results for model_4    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.93      0.97      0.95      6567\n",
            "       B-PER       0.81      0.64      0.72       434\n",
            "       I-PER       0.87      0.73      0.79       296\n",
            "       B-LOC       0.75      0.77      0.76       343\n",
            "       I-LOC       0.85      0.55      0.67        53\n",
            "       B-ORG       0.77      0.59      0.67       350\n",
            "       I-ORG       0.69      0.39      0.50       200\n",
            "\n",
            "    accuracy                           0.91      8243\n",
            "   macro avg       0.81      0.66      0.72      8243\n",
            "weighted avg       0.90      0.91      0.90      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.93      0.97      0.95      3096\n",
            "       B-PER       0.82      0.66      0.73       200\n",
            "       I-PER       0.88      0.71      0.78       157\n",
            "       B-LOC       0.78      0.75      0.76       183\n",
            "       I-LOC       0.92      0.48      0.63        23\n",
            "       B-ORG       0.66      0.58      0.62       168\n",
            "       I-ORG       0.71      0.44      0.54       116\n",
            "\n",
            "    accuracy                           0.90      3943\n",
            "   macro avg       0.81      0.66      0.72      3943\n",
            "weighted avg       0.90      0.90      0.90      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.93      0.98      0.95   1616269\n",
            "      OTHERS       0.89      0.73      0.80    423980\n",
            "\n",
            "    accuracy                           0.92   2040249\n",
            "   macro avg       0.91      0.85      0.88   2040249\n",
            "weighted avg       0.92      0.92      0.92   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.93      0.98      0.95    380877\n",
            "      OTHERS       0.90      0.75      0.82    113647\n",
            "\n",
            "    accuracy                           0.92    494524\n",
            "   macro avg       0.91      0.86      0.88    494524\n",
            "weighted avg       0.92      0.92      0.92    494524\n",
            "\n",
            "****************    Results for model_5    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.98      0.96      6567\n",
            "       B-PER       0.78      0.70      0.74       434\n",
            "       I-PER       0.80      0.77      0.79       296\n",
            "       B-LOC       0.80      0.80      0.80       343\n",
            "       I-LOC       0.84      0.58      0.69        53\n",
            "       B-ORG       0.77      0.62      0.68       350\n",
            "       I-ORG       0.75      0.44      0.55       200\n",
            "\n",
            "    accuracy                           0.92      8243\n",
            "   macro avg       0.81      0.70      0.74      8243\n",
            "weighted avg       0.91      0.92      0.91      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.95      0.98      0.96      3096\n",
            "       B-PER       0.86      0.74      0.80       200\n",
            "       I-PER       0.87      0.79      0.83       157\n",
            "       B-LOC       0.84      0.83      0.83       183\n",
            "       I-LOC       0.65      0.57      0.60        23\n",
            "       B-ORG       0.80      0.65      0.72       168\n",
            "       I-ORG       0.84      0.48      0.61       116\n",
            "\n",
            "    accuracy                           0.93      3943\n",
            "   macro avg       0.83      0.72      0.77      3943\n",
            "weighted avg       0.92      0.93      0.92      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.98      0.96   1616269\n",
            "      OTHERS       0.90      0.77      0.83    423980\n",
            "\n",
            "    accuracy                           0.94   2040249\n",
            "   macro avg       0.92      0.88      0.90   2040249\n",
            "weighted avg       0.93      0.94      0.93   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.95      0.98      0.96    380877\n",
            "      OTHERS       0.94      0.81      0.87    113647\n",
            "\n",
            "    accuracy                           0.94    494524\n",
            "   macro avg       0.94      0.90      0.92    494524\n",
            "weighted avg       0.94      0.94      0.94    494524\n",
            "\n",
            "****************    Results for model_6    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.95      0.98      0.96      6567\n",
            "       B-PER       0.83      0.74      0.78       434\n",
            "       I-PER       0.84      0.77      0.80       296\n",
            "       B-LOC       0.82      0.73      0.77       343\n",
            "       I-LOC       0.89      0.45      0.60        53\n",
            "       B-ORG       0.65      0.63      0.64       350\n",
            "       I-ORG       0.67      0.46      0.54       200\n",
            "\n",
            "    accuracy                           0.91      8243\n",
            "   macro avg       0.80      0.68      0.73      8243\n",
            "weighted avg       0.91      0.91      0.91      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.98      0.96      3096\n",
            "       B-PER       0.84      0.75      0.79       200\n",
            "       I-PER       0.87      0.80      0.83       157\n",
            "       B-LOC       0.88      0.73      0.80       183\n",
            "       I-LOC       0.90      0.39      0.55        23\n",
            "       B-ORG       0.69      0.71      0.70       168\n",
            "       I-ORG       0.77      0.47      0.59       116\n",
            "\n",
            "    accuracy                           0.92      3943\n",
            "   macro avg       0.84      0.69      0.75      3943\n",
            "weighted avg       0.92      0.92      0.92      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.98      0.96   1616269\n",
            "      OTHERS       0.89      0.78      0.83    423980\n",
            "\n",
            "    accuracy                           0.93   2040249\n",
            "   macro avg       0.92      0.88      0.89   2040249\n",
            "weighted avg       0.93      0.93      0.93   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.98      0.96    380877\n",
            "      OTHERS       0.93      0.80      0.86    113647\n",
            "\n",
            "    accuracy                           0.94    494524\n",
            "   macro avg       0.94      0.89      0.91    494524\n",
            "weighted avg       0.94      0.94      0.94    494524\n",
            "\n",
            "****************    Results for model_7    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.95      0.95      6567\n",
            "       B-PER       0.78      0.71      0.74       434\n",
            "       I-PER       0.89      0.73      0.80       296\n",
            "       B-LOC       0.83      0.75      0.79       343\n",
            "       I-LOC       0.90      0.51      0.65        53\n",
            "       B-ORG       0.52      0.67      0.58       350\n",
            "       I-ORG       0.58      0.44      0.50       200\n",
            "\n",
            "    accuracy                           0.90      8243\n",
            "   macro avg       0.78      0.68      0.72      8243\n",
            "weighted avg       0.90      0.90      0.89      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.93      0.96      0.95      3096\n",
            "       B-PER       0.79      0.71      0.75       200\n",
            "       I-PER       0.87      0.75      0.80       157\n",
            "       B-LOC       0.81      0.73      0.76       183\n",
            "       I-LOC       1.00      0.39      0.56        23\n",
            "       B-ORG       0.54      0.68      0.60       168\n",
            "       I-ORG       0.67      0.41      0.51       116\n",
            "\n",
            "    accuracy                           0.90      3943\n",
            "   macro avg       0.80      0.66      0.71      3943\n",
            "weighted avg       0.90      0.90      0.89      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.96      0.95   1616269\n",
            "      OTHERS       0.82      0.77      0.79    423980\n",
            "\n",
            "    accuracy                           0.92   2040249\n",
            "   macro avg       0.88      0.86      0.87   2040249\n",
            "weighted avg       0.91      0.92      0.92   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.93      0.96      0.95    380877\n",
            "      OTHERS       0.85      0.77      0.81    113647\n",
            "\n",
            "    accuracy                           0.92    494524\n",
            "   macro avg       0.89      0.87      0.88    494524\n",
            "weighted avg       0.92      0.92      0.92    494524\n",
            "\n",
            "****************    Results for model_8    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.95      0.97      0.96      6567\n",
            "       B-PER       0.75      0.75      0.75       434\n",
            "       I-PER       0.79      0.74      0.76       296\n",
            "       B-LOC       0.82      0.76      0.79       343\n",
            "       I-LOC       0.85      0.62      0.72        53\n",
            "       B-ORG       0.74      0.63      0.69       350\n",
            "       I-ORG       0.61      0.48      0.54       200\n",
            "\n",
            "    accuracy                           0.91      8243\n",
            "   macro avg       0.79      0.71      0.74      8243\n",
            "weighted avg       0.91      0.91      0.91      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.95      0.97      0.96      3096\n",
            "       B-PER       0.78      0.75      0.76       200\n",
            "       I-PER       0.82      0.77      0.79       157\n",
            "       B-LOC       0.83      0.78      0.80       183\n",
            "       I-LOC       0.77      0.43      0.56        23\n",
            "       B-ORG       0.73      0.65      0.69       168\n",
            "       I-ORG       0.66      0.54      0.59       116\n",
            "\n",
            "    accuracy                           0.91      3943\n",
            "   macro avg       0.79      0.70      0.74      3943\n",
            "weighted avg       0.91      0.91      0.91      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.95      0.97      0.96   1616269\n",
            "      OTHERS       0.87      0.79      0.83    423980\n",
            "\n",
            "    accuracy                           0.93   2040249\n",
            "   macro avg       0.91      0.88      0.89   2040249\n",
            "weighted avg       0.93      0.93      0.93   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.97      0.96    380877\n",
            "      OTHERS       0.89      0.81      0.85    113647\n",
            "\n",
            "    accuracy                           0.93    494524\n",
            "   macro avg       0.92      0.89      0.90    494524\n",
            "weighted avg       0.93      0.93      0.93    494524\n",
            "\n",
            "****************    Results for model_9    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.95      0.97      0.96      6567\n",
            "       B-PER       0.78      0.74      0.76       434\n",
            "       I-PER       0.81      0.78      0.80       296\n",
            "       B-LOC       0.81      0.76      0.79       343\n",
            "       I-LOC       0.75      0.62      0.68        53\n",
            "       B-ORG       0.81      0.60      0.69       350\n",
            "       I-ORG       0.68      0.57      0.62       200\n",
            "\n",
            "    accuracy                           0.92      8243\n",
            "   macro avg       0.80      0.72      0.76      8243\n",
            "weighted avg       0.91      0.92      0.91      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.98      0.96      3096\n",
            "       B-PER       0.76      0.72      0.74       200\n",
            "       I-PER       0.85      0.75      0.80       157\n",
            "       B-LOC       0.85      0.80      0.82       183\n",
            "       I-LOC       0.93      0.57      0.70        23\n",
            "       B-ORG       0.75      0.60      0.66       168\n",
            "       I-ORG       0.67      0.48      0.56       116\n",
            "\n",
            "    accuracy                           0.91      3943\n",
            "   macro avg       0.82      0.70      0.75      3943\n",
            "weighted avg       0.91      0.91      0.91      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.95      0.97      0.96   1616269\n",
            "      OTHERS       0.88      0.80      0.83    423980\n",
            "\n",
            "    accuracy                           0.93   2040249\n",
            "   macro avg       0.91      0.88      0.90   2040249\n",
            "weighted avg       0.93      0.93      0.93   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.98      0.96    380877\n",
            "      OTHERS       0.92      0.79      0.85    113647\n",
            "\n",
            "    accuracy                           0.94    494524\n",
            "   macro avg       0.93      0.89      0.91    494524\n",
            "weighted avg       0.94      0.94      0.93    494524\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM74r0_8nk5s"
      },
      "source": [
        "**Task 6:** Download the GloVe embeddings from https://nlp.stanford.edu/projects/glove/ (use the 300-dim vectors from glove.6B.zip). Then intialize the nn.Embedding module in your NERNet with these embeddings, so that you can start your training with pre-trained vectors. Repeat Task 6 and print the results for each model.\n",
        "\n",
        "Note: make sure that vectors are aligned with the IDs in your Vocab, in other words, make sure that for example the word with ID 0 is the first vector in the GloVe matrix of vectors that you initialize nn.Embedding with. For a dicussion on how to do that, check it this link:\n",
        "https://discuss.pytorch.org/t/can-we-use-pre-trained-word-embeddings-for-weight-initialization-in-nn-embedding/1222"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRiMbvx9o5Rh",
        "outputId": "6f53d29b-b961-4d71-8ca5-e2730fa382fc"
      },
      "source": [
        "# TODO - your code goes here...\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "GLOVE_PATH = 'glove.6B.300d.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-20 18:10:05--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-06-20 18:10:05--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-06-20 18:10:06--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.95MB/s    in 2m 44s  \n",
            "\n",
            "2021-06-20 18:12:50 (5.02 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "249pf4wkMxoC",
        "outputId": "712e01f7-4a47-4242-d64a-0c637f2bd684"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip  sample_data\n",
            "glove.6B.200d.txt  glove.6B.50d.txt   nlp-course\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La9XtK8sN-g9"
      },
      "source": [
        "def get_glove_pre_trained_embeddings_weights(input_size, embedding_size, word2id = vocab.word2id):\n",
        "    weights = np.zeros((input_size, embedding_size))\n",
        "\n",
        "    with open(GLOVE_PATH) as glove:\n",
        "        for line in glove.readlines():\n",
        "            split = line.split()\n",
        "            word = split[0]\n",
        "            word_id = word2id.get(word)\n",
        "\n",
        "        if word_id:\n",
        "            weights[word_id] = split[1:]\n",
        "\n",
        "    return torch.from_numpy(weights).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yywvqfZlMCGg"
      },
      "source": [
        "class GloveNERNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, n_layers, directions):\n",
        "        super(GloveNERNet, self).__init__()\n",
        "        \n",
        "        # TODO: your code...\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "        pre_trained_weights = get_glove_pre_trained_embeddings_weights(input_size, embedding_size)\n",
        "        self.embedding.weight = nn.Parameter(pre_trained_weights)\n",
        "\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_size, hidden_size, n_layers, bidirectional=(True if directions==2 else False))\n",
        "        self.out = nn.Linear(hidden_size*directions, output_size)\n",
        "    \n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.directions = directions\n",
        "\n",
        "\n",
        "    def forward(self, input_sentence):\n",
        "        # TODO: your code...\n",
        "        dimension = len(input_sentence)\n",
        "\n",
        "        # Maybe not needed:\n",
        "        # hidden_state = torch.randn(self.n_layers * self.directions, 1, self.hidden_size).cuda()\n",
        "        # cell_state = torch.randn(self.n_layers * self.directions, 1, self.hidden_size).cuda()\n",
        "        # hidden = (hidden_state, cell_state)\n",
        "        hidden = None\n",
        "\n",
        "        # 1. embed the sentence\n",
        "        embedded = self.embedding(input_sentence)\n",
        "\n",
        "        # 2. give the embedding to LSTM\n",
        "        # \"If (h_0, c_0) is not provided, both h_0 and c_0 default to zero\" (https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
        "        lstm_output, _ = self.lstm(embedded.view(dimension, 1, -1), hidden) # The view function is meant to reshape the tensor https://stackoverflow.com/a/48650355/7786691\n",
        "\n",
        "        # 3. run output through prediction function\n",
        "        output = self.out(lstm_output.view(dimension, -1)) # Applies a linear transformation to the incoming data\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-S9ts7MQ15X"
      },
      "source": [
        "EMBEDDING_SIZE = 300\n",
        "EPOCHS = 10 # change to 10\n",
        "INPUT_SIZE = len(vocab.word2id) # 8955\n",
        "OUTPUT_SIZE = len(vocab.tag2id) # 7\n",
        "\n",
        "model_glove_1 = GloveNERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 1, 1).cuda()\n",
        "train_loop(model_glove_1, EPOCHS)\n",
        "\n",
        "model_glove_2 = GloveNERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 2, 1).cuda()\n",
        "train_loop(model_glove_2, EPOCHS)\n",
        "\n",
        "model_glove_3 = GloveNERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 3, 1).cuda()\n",
        "train_loop(model_glove_3, EPOCHS)\n",
        "\n",
        "model_glove_4 = GloveNERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 1, 2).cuda()\n",
        "train_loop(model_glove_4, EPOCHS)\n",
        "\n",
        "model_glove_5 = GloveNERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 2, 2).cuda()\n",
        "train_loop(model_glove_5, EPOCHS)\n",
        "\n",
        "model_glove_6 = GloveNERNet(INPUT_SIZE, EMBEDDING_SIZE, 500, OUTPUT_SIZE, 3, 2).cuda()\n",
        "train_loop(model_glove_6, EPOCHS)\n",
        "\n",
        "model_glove_7 = GloveNERNet(INPUT_SIZE, EMBEDDING_SIZE, 800, OUTPUT_SIZE, 1, 2).cuda()\n",
        "train_loop(model_glove_7, EPOCHS)\n",
        "\n",
        "model_glove_8 = GloveNERNet(INPUT_SIZE, EMBEDDING_SIZE, 800, OUTPUT_SIZE, 2, 2).cuda()\n",
        "train_loop(model_glove_8, EPOCHS)\n",
        "\n",
        "model_glove_9 = GloveNERNet(INPUT_SIZE, EMBEDDING_SIZE, 800, OUTPUT_SIZE, 3, 2).cuda()\n",
        "train_loop(model_glove_9, EPOCHS)\n",
        "\n",
        "\n",
        "models_glove = [model_glove_1, model_glove_2, model_glove_3, model_glove_4, model_glove_5,\n",
        "          model_glove_6, model_glove_7, model_glove_8, model_glove_9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4u2xduDU7-f",
        "outputId": "f173c7b8-ed93-40f2-8273-9bd8b8f4672f"
      },
      "source": [
        "for i, model in enumerate(models_glove, start=1):\n",
        "    model_name = \"model_glove_\"+str(i)\n",
        "    evaluate(model, model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************    Results for model_glove_1    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.98      0.90      0.94      6567\n",
            "       B-PER       0.88      0.69      0.78       434\n",
            "       I-PER       0.86      0.68      0.76       296\n",
            "       B-LOC       0.81      0.79      0.80       343\n",
            "       I-LOC       0.66      0.72      0.68        53\n",
            "       B-ORG       0.48      0.80      0.60       350\n",
            "       I-ORG       0.25      0.83      0.38       200\n",
            "\n",
            "    accuracy                           0.87      8243\n",
            "   macro avg       0.70      0.77      0.71      8243\n",
            "weighted avg       0.92      0.87      0.89      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.98      0.91      0.95      3096\n",
            "       B-PER       0.89      0.72      0.80       200\n",
            "       I-PER       0.87      0.66      0.75       157\n",
            "       B-LOC       0.85      0.85      0.85       183\n",
            "       I-LOC       0.67      0.52      0.59        23\n",
            "       B-ORG       0.48      0.76      0.59       168\n",
            "       I-ORG       0.31      0.81      0.45       116\n",
            "\n",
            "    accuracy                           0.88      3943\n",
            "   macro avg       0.72      0.75      0.71      3943\n",
            "weighted avg       0.92      0.88      0.89      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.98      0.90      0.94   1616269\n",
            "      OTHERS       0.71      0.94      0.81    423980\n",
            "\n",
            "    accuracy                           0.91   2040249\n",
            "   macro avg       0.84      0.92      0.87   2040249\n",
            "weighted avg       0.92      0.91      0.91   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.98      0.91      0.94    380877\n",
            "      OTHERS       0.76      0.93      0.84    113647\n",
            "\n",
            "    accuracy                           0.92    494524\n",
            "   macro avg       0.87      0.92      0.89    494524\n",
            "weighted avg       0.93      0.92      0.92    494524\n",
            "\n",
            "****************    Results for model_glove_2    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.99      0.86      0.92      6567\n",
            "       B-PER       0.92      0.60      0.72       434\n",
            "       I-PER       0.84      0.62      0.71       296\n",
            "       B-LOC       0.91      0.74      0.82       343\n",
            "       I-LOC       0.74      0.60      0.67        53\n",
            "       B-ORG       0.26      0.81      0.39       350\n",
            "       I-ORG       0.26      0.83      0.39       200\n",
            "\n",
            "    accuracy                           0.83      8243\n",
            "   macro avg       0.70      0.72      0.66      8243\n",
            "weighted avg       0.93      0.83      0.86      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.99      0.87      0.93      3096\n",
            "       B-PER       0.96      0.56      0.70       200\n",
            "       I-PER       0.97      0.61      0.75       157\n",
            "       B-LOC       0.92      0.79      0.85       183\n",
            "       I-LOC       0.75      0.52      0.62        23\n",
            "       B-ORG       0.26      0.80      0.39       168\n",
            "       I-ORG       0.30      0.79      0.43       116\n",
            "\n",
            "    accuracy                           0.83      3943\n",
            "   macro avg       0.73      0.70      0.67      3943\n",
            "weighted avg       0.93      0.83      0.86      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.99      0.86      0.92   1616269\n",
            "      OTHERS       0.64      0.98      0.78    423980\n",
            "\n",
            "    accuracy                           0.88   2040249\n",
            "   macro avg       0.82      0.92      0.85   2040249\n",
            "weighted avg       0.92      0.88      0.89   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.99      0.87      0.92    380877\n",
            "      OTHERS       0.68      0.96      0.80    113647\n",
            "\n",
            "    accuracy                           0.89    494524\n",
            "   macro avg       0.84      0.91      0.86    494524\n",
            "weighted avg       0.92      0.89      0.90    494524\n",
            "\n",
            "****************    Results for model_glove_3    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.99      0.85      0.92      6567\n",
            "       B-PER       0.87      0.65      0.74       434\n",
            "       I-PER       0.70      0.73      0.71       296\n",
            "       B-LOC       0.93      0.70      0.80       343\n",
            "       I-LOC       0.94      0.57      0.71        53\n",
            "       B-ORG       0.26      0.83      0.40       350\n",
            "       I-ORG       0.28      0.81      0.42       200\n",
            "\n",
            "    accuracy                           0.83      8243\n",
            "   macro avg       0.71      0.73      0.67      8243\n",
            "weighted avg       0.92      0.83      0.86      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.99      0.87      0.93      3096\n",
            "       B-PER       0.91      0.62      0.74       200\n",
            "       I-PER       0.81      0.73      0.77       157\n",
            "       B-LOC       0.95      0.74      0.83       183\n",
            "       I-LOC       0.91      0.43      0.59        23\n",
            "       B-ORG       0.26      0.82      0.40       168\n",
            "       I-ORG       0.35      0.78      0.48       116\n",
            "\n",
            "    accuracy                           0.84      3943\n",
            "   macro avg       0.74      0.71      0.68      3943\n",
            "weighted avg       0.93      0.84      0.87      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.99      0.85      0.92   1616269\n",
            "      OTHERS       0.64      0.98      0.77    423980\n",
            "\n",
            "    accuracy                           0.88   2040249\n",
            "   macro avg       0.81      0.92      0.84   2040249\n",
            "weighted avg       0.92      0.88      0.89   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.99      0.87      0.92    380877\n",
            "      OTHERS       0.69      0.97      0.80    113647\n",
            "\n",
            "    accuracy                           0.89    494524\n",
            "   macro avg       0.84      0.92      0.86    494524\n",
            "weighted avg       0.92      0.89      0.90    494524\n",
            "\n",
            "****************    Results for model_glove_4    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.97      0.94      0.96      6567\n",
            "       B-PER       0.92      0.62      0.74       434\n",
            "       I-PER       0.91      0.61      0.73       296\n",
            "       B-LOC       0.83      0.71      0.77       343\n",
            "       I-LOC       0.53      0.66      0.59        53\n",
            "       B-ORG       0.46      0.75      0.57       350\n",
            "       I-ORG       0.33      0.71      0.45       200\n",
            "\n",
            "    accuracy                           0.89      8243\n",
            "   macro avg       0.71      0.72      0.69      8243\n",
            "weighted avg       0.92      0.89      0.90      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.96      0.95      0.96      3096\n",
            "       B-PER       0.88      0.57      0.69       200\n",
            "       I-PER       0.94      0.54      0.68       157\n",
            "       B-LOC       0.85      0.74      0.79       183\n",
            "       I-LOC       0.29      0.48      0.36        23\n",
            "       B-ORG       0.49      0.77      0.60       168\n",
            "       I-ORG       0.41      0.66      0.50       116\n",
            "\n",
            "    accuracy                           0.89      3943\n",
            "   macro avg       0.69      0.67      0.65      3943\n",
            "weighted avg       0.91      0.89      0.89      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.97      0.94      0.96   1616269\n",
            "      OTHERS       0.80      0.89      0.84    423980\n",
            "\n",
            "    accuracy                           0.93   2040249\n",
            "   macro avg       0.88      0.92      0.90   2040249\n",
            "weighted avg       0.94      0.93      0.93   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.96      0.95      0.96    380877\n",
            "      OTHERS       0.85      0.86      0.85    113647\n",
            "\n",
            "    accuracy                           0.93    494524\n",
            "   macro avg       0.90      0.91      0.90    494524\n",
            "weighted avg       0.93      0.93      0.93    494524\n",
            "\n",
            "****************    Results for model_glove_5    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.97      0.95      0.96      6567\n",
            "       B-PER       0.93      0.58      0.71       434\n",
            "       I-PER       0.95      0.54      0.69       296\n",
            "       B-LOC       0.94      0.74      0.83       343\n",
            "       I-LOC       0.85      0.64      0.73        53\n",
            "       B-ORG       0.44      0.78      0.56       350\n",
            "       I-ORG       0.35      0.68      0.46       200\n",
            "\n",
            "    accuracy                           0.89      8243\n",
            "   macro avg       0.77      0.70      0.71      8243\n",
            "weighted avg       0.93      0.89      0.90      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.96      0.96      0.96      3096\n",
            "       B-PER       0.90      0.56      0.69       200\n",
            "       I-PER       0.95      0.48      0.64       157\n",
            "       B-LOC       0.94      0.79      0.86       183\n",
            "       I-LOC       0.71      0.43      0.54        23\n",
            "       B-ORG       0.45      0.80      0.58       168\n",
            "       I-ORG       0.46      0.67      0.55       116\n",
            "\n",
            "    accuracy                           0.90      3943\n",
            "   macro avg       0.77      0.67      0.69      3943\n",
            "weighted avg       0.92      0.90      0.90      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.97      0.95      0.96   1616269\n",
            "      OTHERS       0.83      0.87      0.85    423980\n",
            "\n",
            "    accuracy                           0.94   2040249\n",
            "   macro avg       0.90      0.91      0.91   2040249\n",
            "weighted avg       0.94      0.94      0.94   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.96      0.96      0.96    380877\n",
            "      OTHERS       0.87      0.86      0.86    113647\n",
            "\n",
            "    accuracy                           0.94    494524\n",
            "   macro avg       0.91      0.91      0.91    494524\n",
            "weighted avg       0.94      0.94      0.94    494524\n",
            "\n",
            "****************    Results for model_glove_6    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.96      0.97      0.96      6567\n",
            "       B-PER       0.90      0.69      0.78       434\n",
            "       I-PER       0.95      0.71      0.81       296\n",
            "       B-LOC       0.84      0.72      0.77       343\n",
            "       I-LOC       0.53      0.58      0.55        53\n",
            "       B-ORG       0.57      0.74      0.64       350\n",
            "       I-ORG       0.42      0.62      0.50       200\n",
            "\n",
            "    accuracy                           0.91      8243\n",
            "   macro avg       0.74      0.72      0.72      8243\n",
            "weighted avg       0.92      0.91      0.91      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.95      0.98      0.96      3096\n",
            "       B-PER       0.86      0.69      0.77       200\n",
            "       I-PER       0.95      0.66      0.78       157\n",
            "       B-LOC       0.88      0.80      0.84       183\n",
            "       I-LOC       0.55      0.48      0.51        23\n",
            "       B-ORG       0.61      0.73      0.67       168\n",
            "       I-ORG       0.55      0.57      0.56       116\n",
            "\n",
            "    accuracy                           0.92      3943\n",
            "   macro avg       0.77      0.70      0.73      3943\n",
            "weighted avg       0.92      0.92      0.91      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.96      0.97      0.97   1616269\n",
            "      OTHERS       0.87      0.87      0.87    423980\n",
            "\n",
            "    accuracy                           0.94   2040249\n",
            "   macro avg       0.92      0.92      0.92   2040249\n",
            "weighted avg       0.94      0.94      0.94   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.95      0.97      0.96    380877\n",
            "      OTHERS       0.91      0.82      0.86    113647\n",
            "\n",
            "    accuracy                           0.94    494524\n",
            "   macro avg       0.93      0.90      0.91    494524\n",
            "weighted avg       0.94      0.94      0.94    494524\n",
            "\n",
            "****************    Results for model_glove_7    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.97      0.95      0.96      6567\n",
            "       B-PER       0.91      0.62      0.74       434\n",
            "       I-PER       0.92      0.59      0.72       296\n",
            "       B-LOC       0.79      0.72      0.75       343\n",
            "       I-LOC       0.59      0.57      0.58        53\n",
            "       B-ORG       0.47      0.72      0.57       350\n",
            "       I-ORG       0.32      0.73      0.45       200\n",
            "\n",
            "    accuracy                           0.89      8243\n",
            "   macro avg       0.71      0.70      0.68      8243\n",
            "weighted avg       0.92      0.89      0.90      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.96      0.95      0.96      3096\n",
            "       B-PER       0.84      0.59      0.70       200\n",
            "       I-PER       0.95      0.52      0.67       157\n",
            "       B-LOC       0.87      0.75      0.80       183\n",
            "       I-LOC       0.41      0.39      0.40        23\n",
            "       B-ORG       0.48      0.74      0.59       168\n",
            "       I-ORG       0.38      0.67      0.48       116\n",
            "\n",
            "    accuracy                           0.89      3943\n",
            "   macro avg       0.70      0.66      0.66      3943\n",
            "weighted avg       0.91      0.89      0.89      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.97      0.94      0.96   1616269\n",
            "      OTHERS       0.81      0.89      0.84    423980\n",
            "\n",
            "    accuracy                           0.93   2040249\n",
            "   macro avg       0.89      0.91      0.90   2040249\n",
            "weighted avg       0.94      0.93      0.93   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.96      0.95      0.95    380877\n",
            "      OTHERS       0.84      0.85      0.85    113647\n",
            "\n",
            "    accuracy                           0.93    494524\n",
            "   macro avg       0.90      0.90      0.90    494524\n",
            "weighted avg       0.93      0.93      0.93    494524\n",
            "\n",
            "****************    Results for model_glove_8    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.98      0.93      0.95      6567\n",
            "       B-PER       0.94      0.70      0.80       434\n",
            "       I-PER       0.96      0.69      0.80       296\n",
            "       B-LOC       0.93      0.72      0.81       343\n",
            "       I-LOC       0.76      0.53      0.62        53\n",
            "       B-ORG       0.43      0.82      0.56       350\n",
            "       I-ORG       0.32      0.74      0.45       200\n",
            "\n",
            "    accuracy                           0.89      8243\n",
            "   macro avg       0.76      0.73      0.71      8243\n",
            "weighted avg       0.93      0.89      0.90      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.98      0.94      0.96      3096\n",
            "       B-PER       0.93      0.70      0.80       200\n",
            "       I-PER       0.93      0.63      0.75       157\n",
            "       B-LOC       0.91      0.76      0.83       183\n",
            "       I-LOC       0.53      0.39      0.45        23\n",
            "       B-ORG       0.45      0.85      0.59       168\n",
            "       I-ORG       0.38      0.75      0.51       116\n",
            "\n",
            "    accuracy                           0.89      3943\n",
            "   macro avg       0.73      0.72      0.70      3943\n",
            "weighted avg       0.93      0.89      0.90      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.98      0.93      0.95   1616269\n",
            "      OTHERS       0.78      0.92      0.85    423980\n",
            "\n",
            "    accuracy                           0.93   2040249\n",
            "   macro avg       0.88      0.93      0.90   2040249\n",
            "weighted avg       0.94      0.93      0.93   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.98      0.94      0.96    380877\n",
            "      OTHERS       0.82      0.92      0.87    113647\n",
            "\n",
            "    accuracy                           0.93    494524\n",
            "   macro avg       0.90      0.93      0.91    494524\n",
            "weighted avg       0.94      0.93      0.94    494524\n",
            "\n",
            "****************    Results for model_glove_9    ****************\n",
            "ALL Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.98      0.94      0.96      6567\n",
            "       B-PER       0.92      0.71      0.80       434\n",
            "       I-PER       0.89      0.73      0.80       296\n",
            "       B-LOC       0.97      0.69      0.80       343\n",
            "       I-LOC       0.75      0.51      0.61        53\n",
            "       B-ORG       0.44      0.77      0.56       350\n",
            "       I-ORG       0.35      0.78      0.48       200\n",
            "\n",
            "    accuracy                           0.90      8243\n",
            "   macro avg       0.76      0.73      0.72      8243\n",
            "weighted avg       0.93      0.90      0.91      8243\n",
            "\n",
            "ALL Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.97      0.96      0.96      3096\n",
            "       B-PER       0.86      0.69      0.76       200\n",
            "       I-PER       0.90      0.71      0.79       157\n",
            "       B-LOC       0.95      0.72      0.82       183\n",
            "       I-LOC       0.70      0.30      0.42        23\n",
            "       B-ORG       0.51      0.83      0.63       168\n",
            "       I-ORG       0.40      0.69      0.51       116\n",
            "\n",
            "    accuracy                           0.90      3943\n",
            "   macro avg       0.76      0.70      0.70      3943\n",
            "weighted avg       0.93      0.90      0.91      3943\n",
            "\n",
            "BINARY Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.98      0.94      0.96   1616269\n",
            "      OTHERS       0.81      0.93      0.87    423980\n",
            "\n",
            "    accuracy                           0.94   2040249\n",
            "   macro avg       0.90      0.94      0.91   2040249\n",
            "weighted avg       0.95      0.94      0.94   2040249\n",
            "\n",
            "BINARY Dev Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.97      0.95      0.96    380877\n",
            "      OTHERS       0.86      0.91      0.88    113647\n",
            "\n",
            "    accuracy                           0.94    494524\n",
            "   macro avg       0.92      0.93      0.92    494524\n",
            "weighted avg       0.95      0.94      0.95    494524\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxaESRoco6bV"
      },
      "source": [
        "**Good luck!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgiO4f7JEPTq"
      },
      "source": [
        "# Thank you! :)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}