{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP HW4 - RC - 204502926_311132468_304997067",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-WJBimYDLJS"
      },
      "source": [
        "# Assignment 4\n",
        "Training a simple neural net for relation classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3enPCGBF8FlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ceb6d49-a9ef-4081-ed3e-90b2b47d8e32"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install transformers\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from tabulate import tabulate\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import AutoConfig, AutoModel\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsMpdsEGhfJH",
        "outputId": "35371b53-98b1-441e-d369-550f7ba06679"
      },
      "source": [
        "# constants\n",
        "batch_size = 8\n",
        "epochs = 80\n",
        "lr = 2e-5\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=10).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5QSIEoyDdWh"
      },
      "source": [
        "In this assignment you are required to build a full training and testing pipeline for a neural relation classification (RC), using BERT.\n",
        "\n",
        "The dataset that you will be working on is called SemEval Task 8 dataset (https://arxiv.org/pdf/1911.10422v1.pdf). The dataset contains only train and test split, but you are allowed to split the train dataset into dev if needed.\n",
        "\n",
        "\n",
        "The two files (train and test) are available from the course git repository (https://github.com/kfirbar/nlp-course)\n",
        "\n",
        "\n",
        "In this work we will use the hugingface framework for transformers training and inference. We recomand reading the documentation in https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification *before* you start coding. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ul2Y3vuPoV8"
      },
      "source": [
        "**Task 1:** Write a funtion *read_data* for reading the data from a single file (either train or test). This function recieves a filepath and returns a list of sentence. Every sentence is encoded as a tuple, where the first element is the sentence string and the second the label (also represented as a string). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jwVVxi7DQSa",
        "outputId": "ed9b3cab-ff02-481f-ae37-2826b74ac9e6"
      },
      "source": [
        "!git clone https://github.com/kfirbar/nlp-course"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'nlp-course' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prgzgtt8Jw4Y"
      },
      "source": [
        "def read_data(filepath):\n",
        "    # TODO... write your code accordingly\n",
        "    with open(filepath) as file:\n",
        "        output = file.readlines()\n",
        "\n",
        "    STEP = 4\n",
        "    sentences_indices = np.arange(0, len(output), STEP)\n",
        "    labels_indices = np.arange(1, len(output), STEP)\n",
        "\n",
        "    # for each sentence (filtered by known indices) - remove '\\n' and ignore leading and trailing \\\" chars  \n",
        "    sentences = list(map(lambda i: str(output[i].split('\\t')[1].replace('\\n', '')[1:-1]), sentences_indices))\n",
        "    labels = list(map(lambda i: output[i].replace('\\n', ''), labels_indices))\n",
        "    data = list(zip(sentences, labels))\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "train = read_data('/content/nlp-course/TRAIN_FILE.TXT')\n",
        "test = read_data('/content/nlp-course/TEST_FILE_FULL.TXT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-vKzojSDyEO",
        "outputId": "471cc6f6-d98d-46fb-d7f0-28109acfc9de"
      },
      "source": [
        "train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.',\n",
              " 'Component-Whole(e2,e1)')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuGwk6OwRWGS"
      },
      "source": [
        "Pytorch require the labels to be integers. Create a mapper (dictionary) from the string labels to integers (starting zero). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rKIB5o_vQO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6426c98-ba28-4df9-b116-ee60dec8dbd7"
      },
      "source": [
        "def create_label_mapper(data, remove_entities=False):\n",
        "    # TODO... write your code accordingly\n",
        "    labels = [t[1] for t in data]  # 1 is the position of each label in the list of t tuples\n",
        "\n",
        "    # if we want to remove the (e1,e2) and (e2,e1) strings from the labels\n",
        "    if remove_entities == True:\n",
        "        labels = list(map(lambda l: l.replace('(e1,e2)', '').replace('(e2,e1)', ''), labels))\n",
        "\n",
        "    labels_set = set(labels)  # get unique labels\n",
        "    labels_dict = dict(zip(labels_set, range(len(labels_set))))\n",
        "\n",
        "    return labels_dict\n",
        "\n",
        "\n",
        "labels_dict = create_label_mapper(train, remove_entities=True)\n",
        "labels_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cause-Effect': 7,\n",
              " 'Component-Whole': 6,\n",
              " 'Content-Container': 5,\n",
              " 'Entity-Destination': 1,\n",
              " 'Entity-Origin': 3,\n",
              " 'Instrument-Agency': 9,\n",
              " 'Member-Collection': 4,\n",
              " 'Message-Topic': 8,\n",
              " 'Other': 0,\n",
              " 'Product-Producer': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDKYryfKfNdh"
      },
      "source": [
        "**Task 2:** Write a function *prepare_data* that takes one of the [train, test] datasets and converts each pair of (words, labels) to a pair of indexes. The function also aggregates the samples into batches. BERT uses pretrained tokenization and embedding. you can access the tokenization and indexing using the BertTokenizer class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQe2F0dIhk-M"
      },
      "source": [
        "def prepare_data(data, tokenizer, labels_dict, batch_size=batch_size, remove_entities=True):\n",
        "    data_sequences = []\n",
        "    # TODO - your code...\n",
        "    number_of_batches = math.ceil(len(data) / batch_size)\n",
        "\n",
        "\n",
        "    input_ids, attention_masks, labels = [], [], []\n",
        "\n",
        "    for batch in range(number_of_batches):\n",
        "        batch_sentences = []\n",
        "        batch_labels = []\n",
        "\n",
        "        batch_data_seq = []\n",
        "        batch_start_idx = batch * batch_size\n",
        "        batch_end_idx = batch_start_idx + batch_size\n",
        "\n",
        "        if batch_end_idx > len(data):\n",
        "            batch_end_idx = len(data)\n",
        "\n",
        "        for i in range(batch_start_idx, batch_end_idx):\n",
        "            current_sentence = data[i]\n",
        "            current_text = current_sentence[0]\n",
        "\n",
        "            current_label = current_sentence[1]\n",
        "            if remove_entities == True:\n",
        "                current_label = current_label.replace('(e1,e2)', '').replace('(e2,e1)', '')\n",
        "                current_text = current_text.replace('<e1>', '').replace('<e2>', '').replace('</e1>', '').replace('</e2>', '')\n",
        "\n",
        "            current_label_idx = labels_dict[current_label]\n",
        "\n",
        "            batch_sentences.append(current_text)\n",
        "            batch_labels.append(current_label_idx)\n",
        "\n",
        "\n",
        "        batch_tokend = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")            \n",
        "\n",
        "        b_input_ids, b_attn_mask = batch_tokend['input_ids'], batch_tokend['attention_mask']            \n",
        "\n",
        "        current_sample = (b_input_ids, b_attn_mask, batch_labels)\n",
        "\n",
        "        data_sequences.append(current_sample)\n",
        "\n",
        "    return data_sequences\n",
        "    # return input_ids, attention_masks, labels\n",
        "\n",
        "\n",
        "\n",
        "train_sequences = prepare_data(train, tokenizer, labels_dict)\n",
        "test_sequences = prepare_data(test, tokenizer, labels_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3n4cCb8wpXE"
      },
      "source": [
        "**Task 3:** In this part we classify the sentences using the BertForSequenceClassification model. To save resources, we initialize the optimizer with the final layer of the model. You are also allowed to change the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efvj5qvPxNJE"
      },
      "source": [
        "def get_parameters(params):\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    for name, param in params:   \n",
        "        param.requires_grad = 'classifier' in name\n",
        "        layers.append(param)\n",
        "\n",
        "    return layers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEGSQdeUkTP8"
      },
      "source": [
        "**Task 4:** Write a training loop, which takes a BertForSequenceClassification model and number of epochs to train on. The loss is always CrossEntropyLoss and the optimizer is always Adam. You are allowed to split the train to train and dev sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b61IwkAxKfO"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "\n",
        "def train_loop(model, n_epochs, train_data, dev_data, lr=0.0001):\n",
        "    # Loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    optimizer = torch.optim.Adam(get_parameters(model.named_parameters()), lr=lr)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "    for e in range(1, n_epochs + 1):\n",
        "        # TODO - your code goes here...\n",
        "\n",
        "        for step, batch in enumerate(train_data):\n",
        "\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t for t in batch)\n",
        "            \n",
        "            b_labels = torch.tensor(b_labels).to(device)\n",
        "            model.zero_grad()\n",
        "\n",
        "            \n",
        "            logits = model(b_input_ids.to(device), b_attn_mask.to(device))\n",
        "            logits = logits['logits']\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = criterion(logits, b_labels)\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        print(f\"epoch number: {e} is done\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baN1c_B7lTjb"
      },
      "source": [
        "**Task 5:** write an evaluation loop on a trained model, using the dev and test datasets. This function print the true positive rate (TPR), also known as Recall and the opposite to false positive rate (FPR), also known as precision, of each label seperately (10 labels in total), and for all labels together. The caption argument for the function should be served for printing, so that when you print include it as a prefix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnWD18km6Ere"
      },
      "source": [
        "def evaluate(model, test_data, prefix=\"TEST\"):\n",
        "\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    predictions , true_labels, = [], []\n",
        "    pred_labels = []\n",
        "\n",
        "    # Predict \n",
        "    for batch in test_data:\n",
        "        # Add batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t for t in batch)\n",
        "        \n",
        "        b_labels = torch.tensor(b_labels).to(device)\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and \n",
        "        # speeding up prediction\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "\n",
        "            logits = model(b_input_ids.to(device), b_attn_mask.to(device))\n",
        "            logits = logits['logits']\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "            \n",
        "            # Store predictions and true labels\n",
        "            predictions.append(logits)\n",
        "            true_labels.append(label_ids)\n",
        "\n",
        "\n",
        "    for i in range(len(true_labels)):\n",
        "        pred_labels.append(np.argmax(predictions[i], axis=1))\n",
        "\n",
        "\n",
        "    pred_labels = [val for sublist in pred_labels for val in sublist]\n",
        "    true_labels = [val for sublist in true_labels for val in sublist]\n",
        "\n",
        "    return pred_labels, true_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeBIC443Yvix"
      },
      "source": [
        "def calc_precision_recall(pred_labels, true_labels):\n",
        "\n",
        "    results_dict = dict.fromkeys(labels_dict.keys())\n",
        "\n",
        "    idx_to_labels_dict = {value:key for key, value in labels_dict.items()}\n",
        "\n",
        "    rows =[]\n",
        "    total_precision = 0\n",
        "    total_recall = 0\n",
        "\n",
        "\n",
        "    for key in results_dict.keys():\n",
        "        results_dict[key] = {\"TP\": 0, \"FP\": 0, \"FN\": 0}\n",
        "\n",
        "    for i in range(len(pred_labels)):\n",
        "        pred_label = pred_labels[i]\n",
        "        true_label = true_labels[i]\n",
        "\n",
        "        if pred_label == true_label:\n",
        "            TP_label = idx_to_labels_dict[pred_label]\n",
        "            results_dict[TP_label][\"TP\"] +=1\n",
        "        else:\n",
        "            FP_label = idx_to_labels_dict[pred_label]\n",
        "            FN_label = idx_to_labels_dict[true_label]\n",
        "\n",
        "            results_dict[FP_label][\"FP\"] +=1\n",
        "            results_dict[FN_label][\"FN\"] +=1\n",
        "\n",
        "    for label in results_dict.keys():\n",
        "        TP = results_dict[label][\"TP\"]\n",
        "        FP = results_dict[label][\"FP\"]\n",
        "        FN = results_dict[label][\"FN\"]\n",
        "\n",
        "        precision = TP/(TP+FP)\n",
        "        recall = TP/(TP+FN)\n",
        "\n",
        "        rows.append([label, precision, recall])\n",
        "\n",
        "        total_precision += precision\n",
        "        total_recall += recall\n",
        "    \n",
        "    total_precision /= len(results_dict)\n",
        "    total_recall /= len(results_dict)\n",
        "\n",
        "    rows.append([\"All Together\", total_precision, total_recall])\n",
        "\n",
        "    print(tabulate(rows, headers=['Label', 'Precision', 'Recall'], tablefmt='grid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuHOgUnobOZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb04592-d687-4c5c-87ef-ad796cadc882"
      },
      "source": [
        "model = train_loop(model, n_epochs=epochs, train_data=train_sequences, dev_data=None, lr = lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number: 1 is done\n",
            "epoch number: 2 is done\n",
            "epoch number: 3 is done\n",
            "epoch number: 4 is done\n",
            "epoch number: 5 is done\n",
            "epoch number: 6 is done\n",
            "epoch number: 7 is done\n",
            "epoch number: 8 is done\n",
            "epoch number: 9 is done\n",
            "epoch number: 10 is done\n",
            "epoch number: 11 is done\n",
            "epoch number: 12 is done\n",
            "epoch number: 13 is done\n",
            "epoch number: 14 is done\n",
            "epoch number: 15 is done\n",
            "epoch number: 16 is done\n",
            "epoch number: 17 is done\n",
            "epoch number: 18 is done\n",
            "epoch number: 19 is done\n",
            "epoch number: 20 is done\n",
            "epoch number: 21 is done\n",
            "epoch number: 22 is done\n",
            "epoch number: 23 is done\n",
            "epoch number: 24 is done\n",
            "epoch number: 25 is done\n",
            "epoch number: 26 is done\n",
            "epoch number: 27 is done\n",
            "epoch number: 28 is done\n",
            "epoch number: 29 is done\n",
            "epoch number: 30 is done\n",
            "epoch number: 31 is done\n",
            "epoch number: 32 is done\n",
            "epoch number: 33 is done\n",
            "epoch number: 34 is done\n",
            "epoch number: 35 is done\n",
            "epoch number: 36 is done\n",
            "epoch number: 37 is done\n",
            "epoch number: 38 is done\n",
            "epoch number: 39 is done\n",
            "epoch number: 40 is done\n",
            "epoch number: 41 is done\n",
            "epoch number: 42 is done\n",
            "epoch number: 43 is done\n",
            "epoch number: 44 is done\n",
            "epoch number: 45 is done\n",
            "epoch number: 46 is done\n",
            "epoch number: 47 is done\n",
            "epoch number: 48 is done\n",
            "epoch number: 49 is done\n",
            "epoch number: 50 is done\n",
            "epoch number: 51 is done\n",
            "epoch number: 52 is done\n",
            "epoch number: 53 is done\n",
            "epoch number: 54 is done\n",
            "epoch number: 55 is done\n",
            "epoch number: 56 is done\n",
            "epoch number: 57 is done\n",
            "epoch number: 58 is done\n",
            "epoch number: 59 is done\n",
            "epoch number: 60 is done\n",
            "epoch number: 61 is done\n",
            "epoch number: 62 is done\n",
            "epoch number: 63 is done\n",
            "epoch number: 64 is done\n",
            "epoch number: 65 is done\n",
            "epoch number: 66 is done\n",
            "epoch number: 67 is done\n",
            "epoch number: 68 is done\n",
            "epoch number: 69 is done\n",
            "epoch number: 70 is done\n",
            "epoch number: 71 is done\n",
            "epoch number: 72 is done\n",
            "epoch number: 73 is done\n",
            "epoch number: 74 is done\n",
            "epoch number: 75 is done\n",
            "epoch number: 76 is done\n",
            "epoch number: 77 is done\n",
            "epoch number: 78 is done\n",
            "epoch number: 79 is done\n",
            "epoch number: 80 is done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZU0NWi7bOWt"
      },
      "source": [
        "pred_labels, true_labels = evaluate(model.to(device), test_sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3GHk04TdlhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81704571-df77-4a23-e63f-8df3629f034e"
      },
      "source": [
        "calc_precision_recall(pred_labels, true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Other': {'TP': 354, 'FP': 1439, 'FN': 100}, 'Entity-Destination': {'TP': 15, 'FP': 11, 'FN': 277}, 'Product-Producer': {'TP': 4, 'FP': 10, 'FN': 227}, 'Entity-Origin': {'TP': 12, 'FP': 5, 'FN': 246}, 'Member-Collection': {'TP': 14, 'FP': 5, 'FN': 219}, 'Content-Container': {'TP': 76, 'FP': 82, 'FN': 116}, 'Component-Whole': {'TP': 95, 'FP': 99, 'FN': 217}, 'Cause-Effect': {'TP': 208, 'FP': 276, 'FN': 120}, 'Message-Topic': {'TP': 3, 'FP': 2, 'FN': 258}, 'Instrument-Agency': {'TP': 3, 'FP': 4, 'FN': 153}}\n",
            "+--------------------+-------------+-----------+\n",
            "| Label              |   Precision |    Recall |\n",
            "+====================+=============+===========+\n",
            "| Other              |    0.197434 | 0.779736  |\n",
            "+--------------------+-------------+-----------+\n",
            "| Entity-Destination |    0.576923 | 0.0513699 |\n",
            "+--------------------+-------------+-----------+\n",
            "| Product-Producer   |    0.285714 | 0.017316  |\n",
            "+--------------------+-------------+-----------+\n",
            "| Entity-Origin      |    0.705882 | 0.0465116 |\n",
            "+--------------------+-------------+-----------+\n",
            "| Member-Collection  |    0.736842 | 0.0600858 |\n",
            "+--------------------+-------------+-----------+\n",
            "| Content-Container  |    0.481013 | 0.395833  |\n",
            "+--------------------+-------------+-----------+\n",
            "| Component-Whole    |    0.489691 | 0.304487  |\n",
            "+--------------------+-------------+-----------+\n",
            "| Cause-Effect       |    0.429752 | 0.634146  |\n",
            "+--------------------+-------------+-----------+\n",
            "| Message-Topic      |    0.6      | 0.0114943 |\n",
            "+--------------------+-------------+-----------+\n",
            "| Instrument-Agency  |    0.428571 | 0.0192308 |\n",
            "+--------------------+-------------+-----------+\n",
            "| All Together       |    0.493182 | 0.232021  |\n",
            "+--------------------+-------------+-----------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjkeUfncUl42"
      },
      "source": [
        "**Task 6:** In this part we'll improve the model accuracy by using a method called \"entity markers - Entity start\". The main idea of this approch is to add special markers ([e1], [\\e1], ...) before and after each of the tagged entities. instead of using the CLS toekn for clasification, we will use the concatination of the embedding of [e1] and [e2] as shown in the image below. The complete method is described in details in the following paper - https://arxiv.org/pdf/1906.03158.pdf (specifically in Section 3.2). To use this method we'll need to create a new data load and a new model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKhIbJuzc_EE"
      },
      "source": [
        "![Capture.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTRk1T81VoXj"
      },
      "source": [
        "The new methods require the usage of special tokens. The following code will add the required tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU8jayVXYGsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c16eb30-3f9a-4f99-bfa5-abaa9bec0024"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenizer_MTB = tokenizer\n",
        "\n",
        "tokenizer_MTB.add_tokens(['<e1>', '</e1>', '<e2>', '</e2>'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IQBC7jQILTG"
      },
      "source": [
        "n_epoch_MTB = 80\n",
        "lr_MTB = 2e-5\n",
        "batch_size_MTB = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2UMaxjFYOB7"
      },
      "source": [
        "Create a new dataloader that add entity markers to the dataset and return their indexes as part of the new sample (the expected sample should be (s, l, i) where s is the sentence embedding, l is the label, and i is a touple with the indexes of the start entities)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTv7d1295g4G"
      },
      "source": [
        "labels_dict_MTB = create_label_mapper(train, remove_entities=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMMMR1kSYnc3"
      },
      "source": [
        "def prepare_data_MTB(data, tokenizer, batch_size=batch_size_MTB):\n",
        "    \n",
        "    data_sequences = []\n",
        "    # TODO - your code...\n",
        "    number_of_batches = math.ceil(len(data) / batch_size)\n",
        "\n",
        "    e1_start=tokenizer.added_tokens_encoder['<e1>']\n",
        "    e2_start=tokenizer.added_tokens_encoder['<e2>']\n",
        "\n",
        "    input_ids, attention_masks, labels, e1_e2_idxs = [], [], [], []\n",
        "\n",
        "    for batch in range(number_of_batches):\n",
        "        batch_sentences = []\n",
        "        batch_labels = []\n",
        "\n",
        "        batch_start_idx = batch * batch_size\n",
        "        batch_end_idx = batch_start_idx + batch_size\n",
        "\n",
        "        if batch_end_idx > len(data):\n",
        "            batch_end_idx = len(data)\n",
        "\n",
        "        for i in range(batch_start_idx, batch_end_idx):\n",
        "            current_sen_label = data[i]\n",
        "            current_sentence = current_sen_label[0]\n",
        "\n",
        "            current_label = current_sen_label[1]\n",
        "            current_label = current_label.replace('(e1,e2)', '').replace('(e2,e1)', '')\n",
        "            \n",
        "            current_label_idx = labels_dict_MTB[current_label]\n",
        "\n",
        "\n",
        "            batch_sentences.append(current_sentence)\n",
        "            batch_labels.append(current_label_idx)\n",
        "\n",
        "\n",
        "        batch_tokend = tokenizer(batch_sentences, max_length = 256, padding='max_length', return_tensors=\"pt\", add_special_tokens=True)            \n",
        "\n",
        "        b_input_ids, b_attn_mask = batch_tokend['input_ids'], batch_tokend['attention_mask']            \n",
        "\n",
        "        batch_e1 = (b_input_ids ==e1_start).nonzero()[:,1] \n",
        "        batch_e2 = (b_input_ids ==e2_start).nonzero()[:,1] \n",
        "\n",
        "        e1_e2_idxs = (batch_e1, batch_e2)\n",
        "\n",
        "        current_sample = ((b_input_ids, b_attn_mask), batch_labels, e1_e2_idxs)\n",
        "\n",
        "        \n",
        "        data_sequences.append(current_sample)\n",
        "    return data_sequences\n",
        "\n",
        "\n",
        "train_sequences_MTB = prepare_data_MTB(train, tokenizer_MTB)\n",
        "test_sequences_MTB = prepare_data_MTB(test, tokenizer_MTB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AztAwecuYyt3"
      },
      "source": [
        "Create a new model that uses the \"entity markers - Entity start\" method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADpFlxPFY5mD"
      },
      "source": [
        "class MTB(nn.Module):\n",
        "    \n",
        "    def __init__(self, base_model_name):\n",
        "        super(MTB, self).__init__()\n",
        "\n",
        "        config = AutoConfig.from_pretrained(base_model_name)\n",
        "        config.num_labels = 10\n",
        "\n",
        "        self.bert = AutoModel.from_pretrained(base_model_name, config=config)\n",
        "\n",
        "        self.bert.resize_token_embeddings(len(tokenizer_MTB))\n",
        "\n",
        "        # TODO - your code...\n",
        "\n",
        "        self.num_labels = config.num_labels\n",
        "        self.hidden_size = config.hidden_size\n",
        "\n",
        "        self.classifier = nn.Linear(self.hidden_size * 2, self.num_labels)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input, index):\n",
        "        \n",
        "        (input_ids, attention_mask) = input\n",
        "        e1 = torch.tensor(index[0])\n",
        "        e2 = torch.tensor(index[1])\n",
        "\n",
        "        e1 =  e1.unsqueeze(-1)\n",
        "        e2 =  e2.unsqueeze(-1)\n",
        "\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "\n",
        "        hidden_states_last = outputs.hidden_states[12].to(device)\n",
        "        \n",
        "        e1_idxes = (e1.repeat(1,self.hidden_size).to(device)).unsqueeze(1)\n",
        "        e2_idxes = (e2.repeat(1,self.hidden_size).to(device)).unsqueeze(1)\n",
        "\n",
        "\n",
        "        e1_hidden_states = torch.gather(hidden_states_last, 1, e1_idxes)\n",
        "        e1_hidden_states = torch.squeeze(e1_hidden_states, dim=1)\n",
        "\n",
        "        e2_hidden_states = torch.gather(hidden_states_last, 1, e2_idxes)\n",
        "        e2_hidden_states = torch.squeeze(e2_hidden_states,dim=1)\n",
        "        \n",
        "        e1_e2_hidden_states = torch.cat((e1_hidden_states, e2_hidden_states), dim=1)\n",
        "\n",
        "        output = self.classifier(e1_e2_hidden_states)\n",
        "        return output\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2osy6SU5qeN"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "\n",
        "def train_loop_MTB(model, n_epochs, train_data, dev_data, lr=0.0001):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(get_parameters(model.named_parameters()), lr=lr)\n",
        "\n",
        "    model.train()\n",
        "    for e in range(1, n_epochs + 1):\n",
        "        # TODO - your code goes here...\n",
        "\n",
        "        total_train_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_data):\n",
        "            (b_input_ids, b_attn_mask), b_labels, e1_e2_idxs  = tuple(t for t in batch)\n",
        "            \n",
        "            b_labels = torch.tensor(b_labels).to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            logits = model((b_input_ids.to(device), b_attn_mask.to(device)), e1_e2_idxs)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = criterion(logits, b_labels)\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        print(f\"epoch number: {e} is done\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JWrkoyBU5VM"
      },
      "source": [
        "def evaluate_MTB(model, test_data, prefix=\"TEST\"):\n",
        "\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    predictions , true_labels, = [], []\n",
        "    pred_labels = []\n",
        "\n",
        "    # Predict \n",
        "    for batch in test_data:\n",
        "        # Add batch to GPU\n",
        "        (b_input_ids, b_attn_mask), b_labels, e1_e2_idxs = tuple(t for t in batch)\n",
        "        \n",
        "        b_labels = torch.tensor(b_labels).to(device)\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and \n",
        "        # speeding up prediction\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "\n",
        "            logits = model((b_input_ids.to(device), b_attn_mask.to(device)), e1_e2_idxs)\n",
        "            # logits = logits['logits']\n",
        "\n",
        "            logits = torch.log_softmax(logits, dim=1)\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "            \n",
        "            # Store predictions and true labels\n",
        "            predictions.append(logits)\n",
        "            true_labels.append(label_ids)\n",
        "\n",
        "\n",
        "    for i in range(len(true_labels)):\n",
        "        pred_labels.append(np.argmax(predictions[i], axis=1))\n",
        "\n",
        "\n",
        "    pred_labels = [val for sublist in pred_labels for val in sublist]\n",
        "    true_labels = [val for sublist in true_labels for val in sublist]\n",
        "\n",
        "    return pred_labels, true_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuwCczHeZjaw"
      },
      "source": [
        "Use the new dataloader and model to train and evaluate the new model as in task 4 and 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Od8KPjL5occ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cca010-c6ea-422d-8aea-baf2ea7c49bf"
      },
      "source": [
        "model_MTB = MTB('bert-base-uncased').to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUISR1uZ5tNM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5e384a-df09-45c1-d70e-785230e77295"
      },
      "source": [
        "model_MTB = train_loop_MTB(model_MTB, n_epoch_MTB, train_sequences_MTB, dev_data=None)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch number: 1 is done\n",
            "epoch number: 2 is done\n",
            "epoch number: 3 is done\n",
            "epoch number: 4 is done\n",
            "epoch number: 5 is done\n",
            "epoch number: 6 is done\n",
            "epoch number: 7 is done\n",
            "epoch number: 8 is done\n",
            "epoch number: 9 is done\n",
            "epoch number: 10 is done\n",
            "epoch number: 11 is done\n",
            "epoch number: 12 is done\n",
            "epoch number: 13 is done\n",
            "epoch number: 14 is done\n",
            "epoch number: 15 is done\n",
            "epoch number: 16 is done\n",
            "epoch number: 17 is done\n",
            "epoch number: 18 is done\n",
            "epoch number: 19 is done\n",
            "epoch number: 20 is done\n",
            "epoch number: 21 is done\n",
            "epoch number: 22 is done\n",
            "epoch number: 23 is done\n",
            "epoch number: 24 is done\n",
            "epoch number: 25 is done\n",
            "epoch number: 26 is done\n",
            "epoch number: 27 is done\n",
            "epoch number: 28 is done\n",
            "epoch number: 29 is done\n",
            "epoch number: 30 is done\n",
            "epoch number: 31 is done\n",
            "epoch number: 32 is done\n",
            "epoch number: 33 is done\n",
            "epoch number: 34 is done\n",
            "epoch number: 35 is done\n",
            "epoch number: 36 is done\n",
            "epoch number: 37 is done\n",
            "epoch number: 38 is done\n",
            "epoch number: 39 is done\n",
            "epoch number: 40 is done\n",
            "epoch number: 41 is done\n",
            "epoch number: 42 is done\n",
            "epoch number: 43 is done\n",
            "epoch number: 44 is done\n",
            "epoch number: 45 is done\n",
            "epoch number: 46 is done\n",
            "epoch number: 47 is done\n",
            "epoch number: 48 is done\n",
            "epoch number: 49 is done\n",
            "epoch number: 50 is done\n",
            "epoch number: 51 is done\n",
            "epoch number: 52 is done\n",
            "epoch number: 53 is done\n",
            "epoch number: 54 is done\n",
            "epoch number: 55 is done\n",
            "epoch number: 56 is done\n",
            "epoch number: 57 is done\n",
            "epoch number: 58 is done\n",
            "epoch number: 59 is done\n",
            "epoch number: 60 is done\n",
            "epoch number: 61 is done\n",
            "epoch number: 62 is done\n",
            "epoch number: 63 is done\n",
            "epoch number: 64 is done\n",
            "epoch number: 65 is done\n",
            "epoch number: 66 is done\n",
            "epoch number: 67 is done\n",
            "epoch number: 68 is done\n",
            "epoch number: 69 is done\n",
            "epoch number: 70 is done\n",
            "epoch number: 71 is done\n",
            "epoch number: 72 is done\n",
            "epoch number: 73 is done\n",
            "epoch number: 74 is done\n",
            "epoch number: 75 is done\n",
            "epoch number: 76 is done\n",
            "epoch number: 77 is done\n",
            "epoch number: 78 is done\n",
            "epoch number: 79 is done\n",
            "epoch number: 80 is done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k46XVrTHZxcu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edce2b35-8aee-46d5-98ec-099e5af4433e"
      },
      "source": [
        "pred_labels_MTB, true_labels_MTB = evaluate_MTB(model_MTB, test_sequences_MTB)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA29waV150P9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8136a40d-1fc9-41e7-c30e-9af9d3d1e3f2"
      },
      "source": [
        "calc_precision_recall(pred_labels_MTB, true_labels_MTB)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Other': {'TP': 239, 'FP': 340, 'FN': 215}, 'Entity-Destination': {'TP': 219, 'FP': 41, 'FN': 73}, 'Product-Producer': {'TP': 169, 'FP': 82, 'FN': 62}, 'Entity-Origin': {'TP': 169, 'FP': 50, 'FN': 89}, 'Member-Collection': {'TP': 180, 'FP': 37, 'FN': 53}, 'Content-Container': {'TP': 160, 'FP': 41, 'FN': 32}, 'Component-Whole': {'TP': 227, 'FP': 48, 'FN': 85}, 'Cause-Effect': {'TP': 290, 'FP': 52, 'FN': 38}, 'Message-Topic': {'TP': 198, 'FP': 50, 'FN': 63}, 'Instrument-Agency': {'TP': 95, 'FP': 30, 'FN': 61}}\n",
            "+--------------------+-------------+----------+\n",
            "| Label              |   Precision |   Recall |\n",
            "+====================+=============+==========+\n",
            "| Other              |    0.412781 | 0.526432 |\n",
            "+--------------------+-------------+----------+\n",
            "| Entity-Destination |    0.842308 | 0.75     |\n",
            "+--------------------+-------------+----------+\n",
            "| Product-Producer   |    0.673307 | 0.731602 |\n",
            "+--------------------+-------------+----------+\n",
            "| Entity-Origin      |    0.771689 | 0.655039 |\n",
            "+--------------------+-------------+----------+\n",
            "| Member-Collection  |    0.829493 | 0.772532 |\n",
            "+--------------------+-------------+----------+\n",
            "| Content-Container  |    0.79602  | 0.833333 |\n",
            "+--------------------+-------------+----------+\n",
            "| Component-Whole    |    0.825455 | 0.727564 |\n",
            "+--------------------+-------------+----------+\n",
            "| Cause-Effect       |    0.847953 | 0.884146 |\n",
            "+--------------------+-------------+----------+\n",
            "| Message-Topic      |    0.798387 | 0.758621 |\n",
            "+--------------------+-------------+----------+\n",
            "| Instrument-Agency  |    0.76     | 0.608974 |\n",
            "+--------------------+-------------+----------+\n",
            "| All Together       |    0.755739 | 0.724824 |\n",
            "+--------------------+-------------+----------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxaESRoco6bV"
      },
      "source": [
        "**Good luck!**"
      ]
    }
  ]
}